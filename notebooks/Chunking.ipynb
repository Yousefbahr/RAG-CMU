{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0m4h0k59WrG",
        "outputId": "1287e5ac-b5a4-4012-dc13-c223508dfb80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting chromadb\n",
            "  Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.2 kB)\n",
            "Collecting langchain_huggingface\n",
            "  Downloading langchain_huggingface-0.3.1-py3-none-any.whl.metadata (996 bytes)\n",
            "Collecting langchain_chroma\n",
            "  Downloading langchain_chroma-0.2.6-py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting langchain_experimental\n",
            "  Downloading langchain_experimental-0.3.4-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.12/dist-packages (0.3.11)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.3.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.11.9)\n",
            "Collecting pybase64>=1.4.1 (from chromadb)\n",
            "  Downloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.37.0)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.12/dist-packages (from chromadb) (2.0.2)\n",
            "Collecting posthog<6.0.0,>=2.4.0 (from chromadb)\n",
            "  Downloading posthog-5.4.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.15.0)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Downloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.37.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.22.1)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.67.1)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.12/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.5.2)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (1.75.1)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Downloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl.metadata (10 kB)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.19.2)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Downloading kubernetes-34.1.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.12/dist-packages (from chromadb) (8.5.0)\n",
            "Requirement already satisfied: pyyaml>=6.0.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (6.0.3)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (14 kB)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.12/dist-packages (from chromadb) (3.11.3)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (0.28.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (13.9.4)\n",
            "Requirement already satisfied: jsonschema>=4.19.0 in /usr/local/lib/python3.12/dist-packages (from chromadb) (4.25.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.3.77)\n",
            "Requirement already satisfied: huggingface-hub>=0.33.4 in /usr/local/lib/python3.12/dist-packages (from langchain_huggingface) (0.35.3)\n",
            "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain_experimental)\n",
            "  Downloading langchain_community-0.3.30-py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (25.0)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.12/dist-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2025.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.33.4->langchain_huggingface) (1.1.10)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=4.19.0->chromadb) (0.27.1)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.12/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Collecting urllib3<2.4.0,>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Downloading durationpy-0.10-py3-none-any.whl.metadata (340 bytes)\n",
            "Requirement already satisfied: langchain<2.0.0,>=0.3.27 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.0.43)\n",
            "Collecting requests (from huggingface-hub>=0.33.4->langchain_huggingface)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.12.15)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.11.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.31)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.4.1)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (1.33)\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (25.9.23)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (5.29.5)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.12/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.3)\n",
            "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.7.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.57 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.70.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.37.0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk>=1.2.0->chromadb) (0.58b0)\n",
            "Collecting backoff>=1.10.0 (from posthog<6.0.0,>=2.4.0->chromadb)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: distro>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from posthog<6.0.0,>=2.4.0->chromadb) (1.9.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic>=1.9->chromadb) (0.4.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->chromadb) (2.19.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (8.3.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.1.1)\n",
            "Collecting uvloop>=0.15.1 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.12/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9.1)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.23.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<1.0.0,>=0.3.70->langchain_huggingface) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (0.25.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.33.4->langchain_huggingface) (3.4.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community<0.4.0,>=0.3.0->langchain_experimental) (3.2.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from requests-oauthlib->kubernetes>=28.1.0->chromadb) (3.3.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community<0.4.0,>=0.3.0->langchain_experimental)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading chromadb-1.1.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/19.9 MB\u001b[0m \u001b[31m91.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_huggingface-0.3.1-py3-none-any.whl (27 kB)\n",
            "Downloading langchain_chroma-0.2.6-py3-none-any.whl (12 kB)\n",
            "Downloading langchain_experimental-0.3.4-py3-none-any.whl (209 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading bcrypt-5.0.0-cp39-abi3-manylinux_2_34_x86_64.whl (278 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading kubernetes-34.1.0-py2.py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m91.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.30-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m98.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mmh3-5.2.0-cp312-cp312-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.3/103.3 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnxruntime-1.23.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (17.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m103.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opentelemetry_exporter_otlp_proto_grpc-1.37.0-py3-none-any.whl (19 kB)\n",
            "Downloading posthog-5.4.0-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.4/105.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pybase64-1.4.2-cp312-cp312-manylinux1_x86_64.manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_5_x86_64.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading durationpy-0.10-py3-none-any.whl (3.9 kB)\n",
            "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.8/510.8 kB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m94.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (452 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.2/452.2 kB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Building wheels for collected packages: pypika\n",
            "  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53803 sha256=c984ee018ca7eaaf2ea2cb9f3c81274ab632243ff83425c49c1439ade75ecde6\n",
            "  Stored in directory: /root/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
            "Successfully built pypika\n",
            "Installing collected packages: pypika, durationpy, uvloop, urllib3, pybase64, mypy-extensions, mmh3, marshmallow, humanfriendly, httptools, bcrypt, backoff, watchfiles, typing-inspect, requests, coloredlogs, posthog, onnxruntime, dataclasses-json, kubernetes, opentelemetry-exporter-otlp-proto-grpc, langchain_huggingface, chromadb, langchain_chroma, langchain-community, langchain_experimental\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.5.0\n",
            "    Uninstalling urllib3-2.5.0:\n",
            "      Successfully uninstalled urllib3-2.5.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 bcrypt-5.0.0 chromadb-1.1.1 coloredlogs-15.0.1 dataclasses-json-0.6.7 durationpy-0.10 httptools-0.6.4 humanfriendly-10.0 kubernetes-34.1.0 langchain-community-0.3.30 langchain_chroma-0.2.6 langchain_experimental-0.3.4 langchain_huggingface-0.3.1 marshmallow-3.26.1 mmh3-5.2.0 mypy-extensions-1.1.0 onnxruntime-1.23.0 opentelemetry-exporter-otlp-proto-grpc-1.37.0 posthog-5.4.0 pybase64-1.4.2 pypika-0.48.9 requests-2.32.5 typing-inspect-0.9.0 urllib3-2.3.0 uvloop-0.21.0 watchfiles-1.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb langchain_huggingface langchain_chroma langchain_experimental langchain_text_splitters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57AqaXUU9u4i"
      },
      "outputs": [],
      "source": [
        "from langchain_core.documents import Document\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_chroma import Chroma, vectorstores\n",
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from langchain_experimental.text_splitter import SemanticChunker\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "import os\n",
        "from langchain_core.prompts import PromptTemplate, FewShotPromptTemplate\n",
        "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Hjp1nDzCfkE"
      },
      "outputs": [],
      "source": [
        "# 334M parameters , the small one is 33.4M\n",
        "model_name = \"BAAI/bge-large-en-v1.5\"\n",
        "model_kwargs = {'device': 'cuda'}\n",
        "encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
        "\n",
        "model = HuggingFaceEmbeddings(\n",
        "    model_name=model_name,\n",
        "    model_kwargs=model_kwargs,\n",
        "    encode_kwargs=encode_kwargs)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sQhnjxE0EqDi"
      },
      "outputs": [],
      "source": [
        "# for cosine similarity\n",
        "# collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        "\n",
        "vector_store = Chroma(\n",
        "    collection_name=\"collection\",\n",
        "    embedding_function=model,\n",
        "    persist_directory=\"./chroma_langchain_db\",\n",
        "    collection_metadata={\"hnsw:space\": \"cosine\"}\n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bt31xkwhE8K0"
      },
      "outputs": [],
      "source": [
        "# before embedding a query append this instruction: \"Generate a representaion for this sentence to retrieve related articles: \"\n",
        "# no need for an instruction for embedding documents\n",
        "\n",
        "\n",
        "# metadata of each document:\n",
        "## - parent_folder: the direct parent folder name\n",
        "## - root_folder: the top root folder name , one of 6: \"events\", \"general_info_and_history\", \"music\", \"food_festivals\", \"museums\", \"sports\", \"tax\", \"operating_budget\"\n",
        "## - file: name of file\n",
        "## - depth: the depth of the article starting from 'docments' folder, for ex: file \"pitts_cultural_trust\" has depth of 2\n",
        "## - path: path of file starting from \"documents\" folder\n",
        "## - title: main title of the text file\n",
        "\n",
        "# WON'T USE HEADING AND SUBHEADING FOR NOW\n",
        "## - heading: one of the main headings of a text file, could be None\n",
        "## - subheading: one of the subheadings of the main heading, if there is any, else None\n",
        "\n",
        "\n",
        "# each chunk should have:\n",
        "  # main title of text file\n",
        "  # heading(could be None),\n",
        "  # subheading(could be None)\n",
        "  # its content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GG1w2vw3igDr"
      },
      "outputs": [],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"BAAI/bge-large-en-v1.5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lB2BEBsZL0kO"
      },
      "outputs": [],
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=20, length_function= lambda x: len(x.split()),\n",
        "                                               separators = [\"\\n\\n\", \" \", \"\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qJvX9w5yCZb"
      },
      "outputs": [],
      "source": [
        "def return_smaller_chunks(chunk, chunker):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "    - chunk (str)\n",
        "    - chunker (): SemanticChunker instance from langchain\n",
        "\n",
        "  Returns:\n",
        "    - result_chunks (List[str]): a list of strings representing the smaller chunks\n",
        "\n",
        "  split the chunk that is exceeding the max number of tokens into smaller chunks semantically with overlap\n",
        "  with each smaller chunk having its title, heading ,and subheading, if available\n",
        "  \"\"\"\n",
        "  # extract heading and subheading , if available\n",
        "  heading = \"\"\n",
        "  subheading = \"\"\n",
        "\n",
        "  chunk_lines = []\n",
        "\n",
        "  for line in chunk.splitlines():\n",
        "    if line[:2] == \"- \":\n",
        "      heading = line\n",
        "\n",
        "\n",
        "    elif line[:2] == \"--\" and line[2:5] != \"---\" :\n",
        "      subheading = line\n",
        "\n",
        "    else:\n",
        "      chunk_lines.append(line)\n",
        "\n",
        "  chunk = \"\\n\".join(chunk_lines)\n",
        "\n",
        "  smaller_chunks = chunker.split_text(chunk)\n",
        "\n",
        "  result_chunks = []\n",
        "\n",
        "  for i, chunk in enumerate(smaller_chunks):\n",
        "    # add heading, and subheading for each smaller chunk\n",
        "    new_chunk = \"\"\n",
        "\n",
        "    if heading:\n",
        "      new_chunk += heading + \"\\n\\n\"\n",
        "\n",
        "    if subheading:\n",
        "      new_chunk += subheading + \"\\n\"\n",
        "\n",
        "    chunk = new_chunk + chunk\n",
        "\n",
        "    result_chunks.append(chunk)\n",
        "\n",
        "  return result_chunks\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mFN3Ronp-ve4"
      },
      "outputs": [],
      "source": [
        "def return_docs(file_path, text_splitter ,max_token_size = 512):\n",
        "  \"\"\"\n",
        "  Args:\n",
        "  - file_path: str, file path starts with 'documents' directory\n",
        "  - text_splitter\n",
        "  - max_token_size\n",
        "\n",
        "  Returns:\n",
        "  - documents: List[Document]\n",
        "\n",
        "  chunking texts based on headings and subheadings\n",
        "  returns a list of documents of type (Document)\n",
        "\n",
        "  each chunk contains:\n",
        "  - main title of text file (first multiple lines until an empty line is detected)\n",
        "  - heading, if there is any (represented in text file by '-')\n",
        "  - subheading, if there is any (represented by '--')\n",
        "  - content\n",
        "  \"\"\"\n",
        "  chunks = []\n",
        "  print(file_path)\n",
        "  with open(file_path, \"r\") as f:\n",
        "    document = f.readlines()\n",
        "\n",
        "  chunk_content = \"\"\n",
        "\n",
        "  # extract title, which could be multiple lines\n",
        "  # a title is defined as the group of subsequent lines until an empty line break\n",
        "  # in this example, the title is the first two lines\n",
        "  \"\"\"\n",
        "  Article 1\n",
        "  Taxes\n",
        "\n",
        "  .....\n",
        "  \"\"\"\n",
        "  for j, line in enumerate(document):\n",
        "    if line.strip(' ') == '\\n':\n",
        "      break\n",
        "\n",
        "  title = \"\".join(document[:j]).rstrip()\n",
        "\n",
        "  current_heading = \"\"\n",
        "  for i, line in enumerate(document[j:], j):\n",
        "\n",
        "    # get new heading with new content\n",
        "    if line[:2] == \"- \":\n",
        "      current_heading = line\n",
        "\n",
        "      if chunk_content.strip() != \"\" and re.fullmatch(r\"^\\n?- (.+)\\n+\", chunk_content) is None:\n",
        "        chunks.append(chunk_content.rstrip())\n",
        "\n",
        "      chunk_content = \"\"\n",
        "\n",
        "    # get new subheading content with same heading\n",
        "    elif (line[:2] == \"--\" and line[2:5] != \"---\" )or i == len(document) - 1:\n",
        "\n",
        "      if re.fullmatch(r\"^\\n?- (.+)\\n+\", chunk_content) is None:\n",
        "        chunks.append(chunk_content.rstrip())\n",
        "\n",
        "      chunk_content = current_heading + \"\\n\"\n",
        "\n",
        "\n",
        "    # remove references\n",
        "    chunk_content += re.sub(r\"\\[\\d+\\]\", \"\", line)\n",
        "\n",
        "\n",
        "  limit_respecting_chunks = []\n",
        "  # if a chunk's tokens exceed model limit, split further\n",
        "  for i, chunk in enumerate(chunks):\n",
        "    # print(chunk, end=\"\\n\\n\")\n",
        "    tokens = tokenizer.encode(chunk, add_special_tokens=True)\n",
        "    # remove 70 tokens to accomodate for the title that will be added, which is a max of three short lines\n",
        "    if len(tokens) > max_token_size - 70:\n",
        "      smaller_chunks = return_smaller_chunks(chunk, text_splitter)\n",
        "      for smaller_chunk in smaller_chunks:\n",
        "        limit_respecting_chunks.append(smaller_chunk)\n",
        "\n",
        "    else:\n",
        "      limit_respecting_chunks.append(chunk)\n",
        "\n",
        "\n",
        "  # add title to each chunk\n",
        "  final_chunks = []\n",
        "\n",
        "  for chunk in limit_respecting_chunks:\n",
        "    chunk = title + \"\\n\\n\" + chunk\n",
        "    final_chunks.append(chunk)\n",
        "\n",
        "\n",
        "  documents = []\n",
        "\n",
        "  if \"/\" in file_path:\n",
        "    splitted_path = file_path.lower().split(\"/\")\n",
        "  # Windows\n",
        "  elif \"\\\\\" in file_path:\n",
        "    splitted_path = file_path.lower().split(\"\\\\\")\n",
        "\n",
        "  else:\n",
        "    FileNotFoundError(\"File path is unusual\", file_path)\n",
        "\n",
        "\n",
        "  # text chunks to documents\n",
        "  for text in final_chunks:\n",
        "\n",
        "    document = Document(\n",
        "      page_content=text,\n",
        "      metadata={\"parent_folder\": splitted_path[-2],\n",
        "              \"root_folder\": splitted_path[1],\n",
        "              \"file\": splitted_path[-1],\n",
        "              \"depth\": len(splitted_path) - 1,\n",
        "              \"path\": file_path,\n",
        "              \"title\": title.lower()}\n",
        "      )\n",
        "\n",
        "    documents.append(document)\n",
        "\n",
        "  return documents\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "okWIDCPVit3h"
      },
      "outputs": [],
      "source": [
        "def vectorize(file_path, db):\n",
        "  \"\"\"\n",
        "  recursively search 'file_path' directory for text files\n",
        "  then transform text file into chunks and add them to the database\n",
        "  \"\"\"\n",
        "  if os.path.isfile(file_path):\n",
        "    docs = return_docs(file_path, text_splitter)\n",
        "    vector_store.add_documents(docs)\n",
        "    return\n",
        "\n",
        "  files = os.listdir(file_path)\n",
        "  for f in files:\n",
        "    path = os.path.join(file_path, f)\n",
        "    vectorize(path, db)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ma3XbuxjmALS",
        "outputId": "1eb7fb84-6dcb-4623-93e5-272f1241c37d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (540 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "documents/Operating_Budget/4_Revenue\n",
            "documents/Operating_Budget/3_five_year_financial_forecast\n",
            "documents/Operating_Budget/0_Budget_Authorizing_Legislation_article_1\n",
            "documents/Operating_Budget/2_budget_guide\n",
            "documents/Operating_Budget/1_American_Rescue_Plan_article_1\n",
            "documents/Operating_Budget/0_Budget_Authorizing_Legislation_article_2\n",
            "documents/Operating_Budget/1_American_Rescue_Plan_article_2\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Solid Waste Trust Fund/Solid Waste Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Regional Asset District - Parks and Recreation Trust Fund/Regional Asset District - Parks and Recreation Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Schenley Park Rink Trust Fund/Schenley Park Rink Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Special Events Trust Fund/Special Events Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Senior Citizens Program Trust Fund/Senior Citizens Program Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Police Secondary Employment Trust Fund/Police Secondary Employment Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Stop the Violence Trust Fund/Stop the Violence Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/HUD Fair Housing Program Trust Fund/HUD Fair Housing Program Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Liquid Fuels Trust Fund/Liquid Fuels Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Three Taxing Bodies Trust Fund/Three Taxing Bodies Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Pittsburgh Partnership Trust Fund/Pittsburgh Partnership Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/EEOC Trust Fund/EEOC Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Parks Tax Trust Fund/Parks Tax Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Shade Tree Trust Fund/Shade Tree Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Community Development Trust Fund/Community Development Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Mellon Park Trust Fund/Mellon Park Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Special Food Service Trust Fund/Special Food Service Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Wayfinders Signage Trust Fund/Wayfinders Signage Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Public Works Trust Fund/Public Works Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Regional Asset District - Public Works Trust Fund/Regional Asset District - Public Works Trust Fund_article\n",
            "documents/Operating_Budget/6_Special_Revenue_Funds/Frick Park Trust Fund/Frick Park Trust Fund_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_summary\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/office_of_mayor\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Office of Immigrant and Refugee Affairs/Office of Immigrant and Refugee Affairs_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Parks and Recreation/Department of Parks and Recreation_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Office of the City Controller/Office of the City Controller_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Innovation and Performance/Department of Innovation and Performance_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Law/Department of Law_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Works/Dep of Public Works, Bureau of Operations/Bureau of Operations_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Works/Department of Public Works_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Works/Dep of Public Works, Bureau of Facilities/Bureau of Facilities_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Works/Dep of Public Works, Bureau of Environmental Services/Bureau of Environmental Services_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Works/Dep Of Public Works, Bureau of Administration/Bureau of Administration_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Finance/Department of Finance_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/city_council\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Human Resources and Civil Service/Department of Human Resources and Civil Service_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Commission on Human Relations/Commission on Human Relations_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Citizen Police Review Board/Citizen Police Review Board_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Citizen Police Review Board/Citizen Police Review Board_table_1\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Citizen Police Review Board/Citizen Police Review Board_table_2\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Citizen Police Review Board/Citizen Police Review Board_table_3\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Office of Municipal Investigations/Office of Municipal Investigations_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Ethics Hearing Board/Ethics Hearing Board_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of City Planning/Department of City Planning_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Office of Equity/Office of Equity_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/expenditures_details\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Safety/Dep of Public Safety, Bureau of Police/Bureau of Police_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Safety/Dep of Public Safety, Office of Community Health and Safety/Office of Community Health and Safety_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Safety/Dep of Public Safety, Bureau of Emergency Medical Services/Bureau of Emergency Medical Services_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Safety/Dep of Public Safety, Bureau of Fire/Bureau of Fire_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Public Safety/Dep of Public Safety, Bureau of Animal Care and Control/Bureau of Animal Care and Control_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Office of Management and Budget/Office of Management and Budget_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Mobility and Infrastructure/Department of Mobility and Infrastructure_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/Department of Permits, Licenses, and Inspections/Department of Permits, Licenses, and Inspections_article\n",
            "documents/Operating_Budget/5_expenditures/expenditures_detail/council_as_a_body\n",
            "documents/tax/institution_&_service/institution_tax_article_3\n",
            "documents/tax/institution_&_service/institution_tax_article_4\n",
            "documents/tax/institution_&_service/institution_tax_article_1\n",
            "documents/tax/institution_&_service/institution_tax_article_6\n",
            "documents/tax/institution_&_service/institution_tax_article_2\n",
            "documents/tax/institution_&_service/institution_tax_article_5\n",
            "documents/tax/institution_&_service/institution_tax_article_7\n",
            "documents/tax/non_resident_sports_usage_fees/non_resident_sports_usage_fees_article_3\n",
            "documents/tax/non_resident_sports_usage_fees/non_resident_sports_usage_fees_article_4\n",
            "documents/tax/non_resident_sports_usage_fees/non_resident_sports_usage_fees_article_5\n",
            "documents/tax/non_resident_sports_usage_fees/non_resident_sports_usage_fees_article_2\n",
            "documents/tax/non_resident_sports_usage_fees/non_resident_sports_usage_fees_article_6\n",
            "documents/tax/non_resident_sports_usage_fees/non_resident_sports_usage_fees_article_1\n",
            "documents/tax/local_services_tax/local_services_tax_article_2\n",
            "documents/tax/local_services_tax/local_services_tax_article_3\n",
            "documents/tax/local_services_tax/local_services_tax_article_4\n",
            "documents/tax/local_services_tax/local_services_tax_article_5\n",
            "documents/tax/local_services_tax/local_services_tax_article_1\n",
            "documents/tax/payroll_expense_tax/payroll_tax_article_1\n",
            "documents/tax/payroll_expense_tax/payroll_tax_article_3\n",
            "documents/tax/payroll_expense_tax/payroll_tax_article_5\n",
            "documents/tax/payroll_expense_tax/payroll_tax_article_2\n",
            "documents/tax/payroll_expense_tax/payroll_tax_article_4\n",
            "documents/tax/payroll_expense_tax/payroll_tax_article_6\n",
            "documents/tax/parking_tax/parking_tax_article_2\n",
            "documents/tax/parking_tax/parking_tax_article_1\n",
            "documents/tax/parking_tax/parking_tax_article_6\n",
            "documents/tax/parking_tax/parking_tax_article_5\n",
            "documents/tax/parking_tax/parking_tax_article_4\n",
            "documents/tax/parking_tax/parking_tax_article_3\n",
            "documents/tax/parking_tax/parking_tax_article_8\n",
            "documents/tax/parking_tax/parking_tax_article_7\n",
            "documents/tax/amusement_tax/amusement_tax_article_4\n",
            "documents/tax/amusement_tax/amusement_tax_article_1\n",
            "documents/tax/amusement_tax/amusement_tax_article_6\n",
            "documents/tax/amusement_tax/amusement_tax_article_2\n",
            "documents/tax/amusement_tax/amusement_tax_article_7\n",
            "documents/tax/amusement_tax/amusement_tax_article_3\n",
            "documents/tax/amusement_tax/amusement_tax_article_5\n",
            "documents/Museums/heinz_history/heinz_history_general\n",
            "documents/Museums/heinz_history/heinz_history_about\n",
            "documents/Museums/other_museums_names\n",
            "documents/Museums/carnegie_museums/carnegie_museum_things_to_do\n",
            "documents/Museums/carnegie_museums/carnegie_museum_general\n",
            "documents/Museums/carnegie_museums/carnegie_museum_about\n",
            "documents/Museums/carnegie_museums/carnegie_museum_event_spaces\n",
            "documents/Museums/frick_museum\n",
            "documents/Events/downtown_pitts/month_3_2024_events\n",
            "documents/Events/downtown_pitts/month_5_2024_events\n",
            "documents/Events/downtown_pitts/month_11_2024_events\n",
            "documents/Events/downtown_pitts/month_9_2024_events\n",
            "documents/Events/downtown_pitts/month_10_2024_events\n",
            "documents/Events/downtown_pitts/month_4_2024_events\n",
            "documents/Events/downtown_pitts/month_6_2024_events\n",
            "documents/Events/downtown_pitts/month_12_2024_events\n",
            "documents/Events/downtown_pitts/month_8_2024_events\n",
            "documents/Events/downtown_pitts/month_7_2024_events\n",
            "documents/Events/downtown_pitts/month_1_2024_events\n",
            "documents/Events/downtown_pitts/month_2_2024_events\n",
            "documents/Events/heinz_history_events/heinz_history_events_sep\n",
            "documents/Events/heinz_history_events/heinz_history_events_august\n",
            "documents/Events/heinz_history_events/heinz_history_events_nov\n",
            "documents/Events/heinz_history_events/heinz_history_events_oct\n",
            "documents/Events/heinz_history_events/heinz_history_events_june\n",
            "documents/Events/heinz_history_events/heinz_history_events_dec\n",
            "documents/Events/heinz_history_events/heinz_history_events_july\n",
            "documents/Events/cmu_events_calender/event_calender_dec\n",
            "documents/Events/cmu_events_calender/event_calender_oct\n",
            "documents/Events/cmu_events_calender/event_calender_sep\n",
            "documents/Events/pitts_city_paper_oct_28_events/Pitts_City_Paper_Events_article_4\n",
            "documents/Events/pitts_city_paper_oct_28_events/Pitts_City_Paper_Events_article_1\n",
            "documents/Events/pitts_city_paper_oct_28_events/Pitts_City_Paper_Events_article_2\n",
            "documents/Events/pitts_city_paper_oct_28_events/Pitts_City_Paper_Events_article_3\n",
            "documents/Events/campus_annual_events\n",
            "documents/sports/steelers\n",
            "documents/sports/penguins\n",
            "documents/sports/pirates\n",
            "documents/sports/sports_general\n",
            "documents/Music/pitts_cultural_trust\n",
            "documents/Music/pitts_symphony\n",
            "documents/Music/pitts_opera\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_thingsToDo_Top25\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_general\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_Events\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_thingsToDo_FamilyFun\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_Hotels\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_thingsToDo_Restaurants\n",
            "documents/General_Info_&_History/pitt_website_webpages/pitt_website_thingsToDo_TopFree\n",
            "documents/General_Info_&_History/Pittsburgh_brittanica\n",
            "documents/General_Info_&_History/history_of_Pittsburgh_wiki\n",
            "documents/General_Info_&_History/about_cmu\n",
            "documents/General_Info_&_History/Pittsburgh_wiki\n",
            "documents/food_festivals/taco_festival\n",
            "documents/food_festivals/little_italy_days\n",
            "documents/food_festivals/restaurant_week_about\n",
            "documents/food_festivals/restaurant_week_history\n",
            "documents/food_festivals/restaurant_week_2024\n",
            "documents/food_festivals/picklesburgh\n",
            "documents/food_festivals/food_festivals\n"
          ]
        }
      ],
      "source": [
        "# saves documents into the database\n",
        "vectorize(\"documents\", vector_store)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}